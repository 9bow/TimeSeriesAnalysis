{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (ML)\n",
    "\n",
    "## 1) Learning Style\n",
    "There are 3 or 4 different ways an algorithm can model a problem.  \n",
    "This taxonomy or way of organizing machine learning algorithms is useful because it forces you to think about the roles of the input data and the model preparation process and select one that is the most appropriate for your problem in order to get the best result.  \n",
    "(Supervised vs Unsupervised vs Semi-supervised vs Reinforcement Learning)  \n",
    "\n",
    "- Overall types of ML (3 Types):  \n",
    "![](https://github.com/cheonbi/DataScience/blob/master/Image/ML_Type_Application_Circle.jpg?raw=true)  \n",
    "<center>(https://nowenlightenme.com/2018/03/18/types-of-machine-learning/)</center>  \n",
    "\n",
    "\n",
    "- With other examples (4 Types):\n",
    "![](https://github.com/cheonbi/DataScience/blob/master/Image/ML_Type_Application.png?raw=true)  \n",
    "<center>(https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861)</center>  \n",
    "\n",
    "\n",
    "- With other examples (Roles):  \n",
    "![](https://github.com/cheonbi/DataScience/blob/master/Image/ML_Type_Glance.jpg?raw=true)  \n",
    "<center>(https://nowenlightenme.com/2018/03/18/types-of-machine-learning/)</center>  \n",
    "\n",
    "|               \t| Supervised Learning \t| Unsupervised Learning \t| Semi-supervised Learning \t|\n",
    "|---------------\t|---------------------\t|-----------------------\t|--------------------------\t|\n",
    "| Input Data    \t| labeled             \t| unlabeled             \t| labeled + unlabeled      \t|\n",
    "| Output Result \t| labeled             \t| unlabeled             \t| labeled + unlabeled      \t|\n",
    "| |<img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Supervised-Learning-Algorithms.png' width='150'>|<img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Unsupervised-Learning-Algorithms.png' width='150'>|<img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Semi-supervised-Learning-Algorithms.png' width='150'>|\n",
    "<center>(https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)</center>  \n",
    "\n",
    "## 2) Algorithms by Learning Style [(Summary)](https://en.wikipedia.org/wiki/Outline_of_machine_learning)\n",
    "\n",
    "### - Supervised Learning\n",
    "\n",
    "| Regression Algorithms | Instance-based Algorithms | Regularization Algorithms | Decision Tree Algorithms | Bayesian Algorithms | Artificial Neural Network Algorithms |\n",
    "|------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Ordinary Least Squares Regression (OLSR) | k-Nearest Neighbor (kNN) | Ridge Regression | Classification and Regression Tree (CART) | Naive Bayes | Perceptron |\n",
    "| Linear Regression | Learning Vector Quantization (LVQ) | Least Absolute Shrinkage and Selection Operator (LASSO) | Iterative Dichotomiser 3 (ID3) | Gaussian Naive Bayes | Back-Propagation |\n",
    "| Logistic Regression | Self-Organizing Map (SOM) | Elastic Net | C4.5 and C5.0 (different versions of a powerful approach) | Multinomial Naive Bayes | Hopfield Network |\n",
    "| Stepwise Regression | Locally Weighted Learning (LWL) | Least-Angle Regression (LARS) | Chi-squared Automatic Interaction Detection (CHAID) | Averaged One-Dependence Estimators (AODE) | Radial Basis Function Network (RBFN) |\n",
    "| Multivariate Adaptive Regression Splines (MARS) |  |  | Decision Stump | Bayesian Belief Network (BBN) |  |\n",
    "| Locally Estimated Scatterplot Smoothing (LOESS) |  |  | M5 | Bayesian Network (BN) |  |\n",
    "|  |  |  | Conditional Decision Trees |  |  |\n",
    "| <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Regression-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Instance-based-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Regularization-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Decision-Tree-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Bayesian-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Artificial-Neural-Network-Algorithms.png' width='150'> |\n",
    "\n",
    "### - Unsupervised Learning  \n",
    "\n",
    "| Clustering Algorithms | Association Rule Learning Algorithms | Dimensionality Reduction Algorithms | Ensemble Algorithms | Deep Learning Algorithms |\n",
    "|------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| k-Means | Apriori algorithm | Principal Component Analysis (PCA) | Boosting | Deep Boltzmann Machine (DBM) |\n",
    "| k-Medians | Eclat algorithm | Principal Component Regression (PCR) | Bootstrapped Aggregation (Bagging) | Deep Belief Networks (DBN) |\n",
    "| Expectation Maximisation (EM) |  | Partial Least Squares Regression (PLSR) | AdaBoost | Convolutional Neural Network (CNN) |\n",
    "| Hierarchical Clustering |  | Sammon Mapping | Stacked Generalization (blending) | Stacked Auto-Encoders |\n",
    "|  |  | Multidimensional Scaling (MDS) | Gradient Boosting Machines (GBM) |  |\n",
    "|  |  | Projection Pursuit | Gradient Boosted Regression Trees (GBRT) |  |\n",
    "|  |  | Linear Discriminant Analysis (LDA) | Random Forest |  |\n",
    "|  |  | Mixture Discriminant Analysis (MDA) |  |  |\n",
    "|  |  | Quadratic Discriminant Analysis (QDA) |  |  |\n",
    "|  |  | Flexible Discriminant Analysis (FDA) |  |  |\n",
    "| <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Clustering-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Assoication-Rule-Learning-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Dimensional-Reduction-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Ensemble-Algorithms.png' width='150'> | <img src='https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Deep-Learning-Algorithms.png' width='150'> |\n",
    "<center>(https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)</center>\n",
    "\n",
    "\n",
    "\n",
    "# Time Series Analysis (TSA)\n",
    "There is a radical change in moving from machine learning to time-series forecasting.  \n",
    "The objective of a predictive model is to estimate the value of an unknown variable. A time series has time ($t$) as an independent variable (in any unit you can think of) and a target dependent variable ($y_t$). The output of the model is the predicted value for $y$ at time $t$, ie. ($\\hat{y_t}$).  \n",
    "\n",
    "Whenever data is recorded at regular intervals of time, it is called a time series. You can think of this type of variable in two ways:  \n",
    "1) The data is univariate, but it has an index (time) that creates an implicit order.  \n",
    "2) The dataset has two dimensions: the time (independent variable) and the variable itself as dependent variable.  \n",
    "\n",
    "If you have experience working in machine learning, you must make some adjustments when working with time series.\n",
    "(https://www.datascience.com/blog/time-series-forecasting-machine-learning-differences)\n",
    "\n",
    "## 1) Time-series features should be handled with care\n",
    "As a data scientist, you may already be used to creating features, either manually (feature engineering) or automatically (feature learning). Either way, creating features is one of the most important and time-consuming tasks in analysis.  \n",
    "\n",
    "However, in time series forecasting, you don’t create features — at least not in the traditional sense. This is especially true when you want to forecast several steps ahead, and not just the following value.  \n",
    "\n",
    "This does not mean that features are completely off limits. Instead, they should be used with care because of the following reasons:  \n",
    "1) It is not clear what the future real values will be for those features.  \n",
    "2) If the features are predictable, i.e., they have some patterns, you can build a forecast model for each of them. However, keep in mind that using predicted values as features will propagate the error to the target variable, which may cause higher errors or produce biased forecasts.  \n",
    "3) A pure time series model may have similar or even better performance than one using features.  \n",
    "\n",
    "Besides, some forecasting models are only based on historical values of the variable, like Exponential Smoothing (ETS) and Autoregressive Integrated Moving Average (ARIMA) models.  \n",
    "\n",
    "Is it also possible to combine time series with feature engineering using time series components and time-based features. The first refers to the properties (components) of a time series, and the latter refers to time-related features, which have definite patterns and can be calculated in a deterministic way. You can add them to any time-series models that can handle predictors.  \n",
    "\n",
    "### - Time Series Components  \n",
    "- Trend: A trend exists when a series increases, decreases, or remains at a constant level with respect to time. \n",
    "- Seasonality: This refers to the property of a time series that displays periodical patterns that repeats at a constant frequency ($m$).  \n",
    "> In the following example, you can observe a seasonal component with $m$ = 12, which means that the periodical pattern repeats every twelve months. (Usually, to handle seasonality, time series models include seasonal variables as dummy features, using $m$—1 binary variables to avoid correlation between features.)\n",
    "- Cycle: Cycles are seasons that do not occur at a fixed rate.  \n",
    "> These do not repeat at regular time intervals and may occur even if the frequency is 1 (m = 1).  \n",
    "\n",
    "<img src='https://www.researchgate.net/profile/Louis_Tay/publication/279249485/figure/fig2/AS:272568091410451@1441996705460/The-original-time-series-decomposed-into-its-trend-seasonal-and-irregular-ie.png' width='800'>\n",
    "<center>(https://www.researchgate.net/figure/The-original-time-series-decomposed-into-its-trend-seasonal-and-irregular-ie_fig2_279249485)</center>\n",
    "\n",
    "- Dummy variables: Similar to how seasonality can be added as a binary feature, other features can be added in binary format to the model. You can add holidays, special events, marketing campaigns, whether a value is outlier or not, etc.  \n",
    "> However, you should remember that these variables need to have definite patterns.  \n",
    "- Number of days: These can be easily calculated even for future months/quarters and may affect forecasts, especially for financial data.  \n",
    "- Lagged values: You can include lagged values of the variable as predictors. Some models like ARIMA, Vector Autoregression (VAR), or Autoregressive Neural Networks (NNAR) work this way.  \n",
    "\n",
    "Time series components are highly important to analyzing the variable of interest in order to understand its behavior, what patterns it has, and to be able to choose and fit an appropriate time-series model. Time series predictors, on the other hand, may help some models to recognize additional patterns and improve the quality of forecasts. Both time series components and features are key to interpreting the behavior of the time series, analyzing its properties, identifying possible causes, and more.  \n",
    "\n",
    "## 2) There may be smaller datasets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Split\n",
    "(https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "\n",
    "# 전처리 및 핸들링 팁\n",
    "(https://sacko.tistory.com/53?category=647946)\n",
    "\n",
    "\n",
    "# 과적합 및 기타 엄청난 강의자료\n",
    "(https://rfriend.tistory.com/187)\n",
    "\n",
    "\n",
    "# 시계열 강의자료\n",
    "(https://otexts.com/fpp2/)  \n",
    "(https://datascienceschool.net/notebook/TIME-SERIES-ANALYSIS/)\n",
    "\n",
    "\n",
    "# 머신러닝 강의록\n",
    "(https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/)\n",
    "\n",
    "# Cheet sheet\n",
    "(https://medium.com/machine-learning-in-practice/cheat-sheet-of-machine-learning-and-python-and-math-cheat-sheets-a4afe4e791b6)  \n",
    "(https://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/)  \n",
    "(https://www.favouriteblog.com/essential-cheat-sheets-for-machine-learning-python-and-maths/)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
