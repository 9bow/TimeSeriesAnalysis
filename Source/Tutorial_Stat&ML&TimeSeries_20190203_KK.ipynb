{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (ML)\n",
    "## 1) Learning Style\n",
    "There are 3 or 4 different ways an algorithm can model a problem.  \n",
    "This taxonomy or way of organizing machine learning algorithms is useful because it forces you to think about the roles of the input data and the model preparation process and select one that is the most appropriate for your problem in order to get the best result.  \n",
    "(Supervised vs Unsupervised vs Semi-supervised vs Reinforcement Learning)  \n",
    "- Overall types of ML (3 Types):  \n",
    "![](https://github.com/cheonbi/DataScience/blob/master/Image/ML_Type_Application_Circle.jpg?raw=true)  \n",
    "(https://nowenlightenme.com/2018/03/18/types-of-machine-learning/)  \n",
    "- With other examples (4 Types):\n",
    "![](https://github.com/cheonbi/DataScience/blob/master/Image/ML_Type_Application.png?raw=true)  \n",
    "(https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861)  \n",
    "- With other examples (Roles):  \n",
    "![](https://github.com/cheonbi/DataScience/blob/master/Image/ML_Type_Glance.jpg?raw=true)  \n",
    "(https://nowenlightenme.com/2018/03/18/types-of-machine-learning/)  \n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Supervised-Learning-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Unsupervised-Learning-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Semi-supervised-Learning-Algorithms.png)  \n",
    "(https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)\n",
    "\n",
    "|               \t| Supervised Learning \t| Unsupervised Learning \t| Semi-supervised Learning \t|\n",
    "|---------------\t|---------------------\t|-----------------------\t|--------------------------\t|\n",
    "| Input Data    \t| labeled             \t| unlabeled             \t| labeled + unlabeled      \t|\n",
    "| Output Result \t| labeled             \t| unlabeled             \t| labeled + unlabeled      \t|\n",
    "\n",
    "## 2) Algorithms by Learning Style [(Summary)](https://en.wikipedia.org/wiki/Outline_of_machine_learning)\n",
    "- Supervised Learning  \n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Regression-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Instance-based-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Regularization-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Decision-Tree-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Bayesian-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Artificial-Neural-Network-Algorithms.png)\n",
    "\n",
    "| Regression   Algorithms                           \t| Instance-based Algorithms          \t| Regularization Algorithms                               \t| Decision Tree Algorithms                                  \t| Bayesian Algorithms                       \t| Artificial Neural Network Algorithms \t|\n",
    "|---------------------------------------------------\t|------------------------------------\t|---------------------------------------------------------\t|-----------------------------------------------------------\t|-------------------------------------------\t|--------------------------------------\t|\n",
    "| Ordinary   Least Squares Regression (OLSR)        \t| k-Nearest Neighbor (kNN)           \t| Ridge Regression                                        \t| Classification and Regression Tree (CART)                 \t| Naive Bayes                               \t| Perceptron                           \t|\n",
    "| Linear Regression                                 \t| Learning Vector Quantization (LVQ) \t| Least Absolute Shrinkage and Selection Operator (LASSO) \t| Iterative Dichotomiser 3 (ID3)                            \t| Gaussian Naive Bayes                      \t| Back-Propagation                     \t|\n",
    "| Logistic Regression                               \t| Self-Organizing Map (SOM)          \t| Elastic Net                                             \t| C4.5 and C5.0 (different versions of a powerful approach) \t| Multinomial Naive Bayes                   \t| Hopfield Network                     \t|\n",
    "| Stepwise Regression                               \t| Locally Weighted Learning (LWL)    \t| Least-Angle Regression (LARS)                           \t| Chi-squared Automatic Interaction Detection (CHAID)       \t| Averaged One-Dependence Estimators (AODE) \t| Radial Basis Function Network (RBFN) \t|\n",
    "| Multivariate Adaptive Regression Splines   (MARS) \t|                                    \t|                                                         \t| Decision Stump                                            \t| Bayesian Belief Network (BBN)             \t|                                      \t|\n",
    "| Locally Estimated Scatterplot Smoothing   (LOESS) \t|                                    \t|                                                         \t| M5                                                        \t| Bayesian Network (BN)                     \t|                                      \t|\n",
    "|                                                   \t|                                    \t|                                                         \t| Conditional Decision Trees                                \t|                                           \t|                                      \t|\n",
    "- Unsupervised Learning  \n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Clustering-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Assoication-Rule-Learning-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Dimensional-Reduction-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Ensemble-Algorithms.png)\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2013/11/Deep-Learning-Algorithms.png)\n",
    "\n",
    "| Clustering   Algorithms       \t| Association Rule Learning Algorithms \t| Dimensionality Reduction Algorithms     \t| Ensemble Algorithms                      \t| Deep Learning Algorithms           \t|\n",
    "|-------------------------------\t|--------------------------------------\t|-----------------------------------------\t|------------------------------------------\t|------------------------------------\t|\n",
    "| k-Means                       \t| Apriori algorithm                    \t| Principal Component Analysis (PCA)      \t| Boosting                                 \t| Deep Boltzmann Machine (DBM)       \t|\n",
    "| k-Medians                     \t| Eclat algorithm                      \t| Principal Component Regression (PCR)    \t| Bootstrapped Aggregation (Bagging)       \t| Deep Belief Networks (DBN)         \t|\n",
    "| Expectation Maximisation (EM) \t|                                      \t| Partial Least Squares Regression (PLSR) \t| AdaBoost                                 \t| Convolutional Neural Network (CNN) \t|\n",
    "| Hierarchical Clustering       \t|                                      \t| Sammon Mapping                          \t| Stacked Generalization (blending)        \t| Stacked Auto-Encoders              \t|\n",
    "|                               \t|                                      \t| Multidimensional Scaling (MDS)          \t| Gradient Boosting Machines (GBM)         \t|                                    \t|\n",
    "|                               \t|                                      \t| Projection Pursuit                      \t| Gradient Boosted Regression Trees (GBRT) \t|                                    \t|\n",
    "|                               \t|                                      \t| Linear Discriminant Analysis (LDA)      \t| Random Forest                            \t|                                    \t|\n",
    "|                               \t|                                      \t| Mixture Discriminant Analysis (MDA)     \t|                                          \t|                                    \t|\n",
    "|                               \t|                                      \t| Quadratic Discriminant Analysis (QDA)   \t|                                          \t|                                    \t|\n",
    "|                               \t|                                      \t| Flexible Discriminant Analysis (FDA)    \t|                                          \t|                                    \t|\n",
    "(https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)\n",
    "\n",
    "# Time Series Analysis (TSA)\n",
    "There is a radical change in moving from machine learning to time-series forecasting.  \n",
    "The objective of a predictive model is to estimate the value of an unknown variable. A time series has time ($t$) as an independent variable (in any unit you can think of) and a target dependent variable ($y_t$). The output of the model is the predicted value for $y$ at time $t$, ie. ($\\hat{y_t}$).  \n",
    "\n",
    "Whenever data is recorded at regular intervals of time, it is called a time series. You can think of this type of variable in two ways:  \n",
    "1) The data is univariate, but it has an index (time) that creates an implicit order.  \n",
    "2) The dataset has two dimensions: the time (independent variable) and the variable itself as dependent variable.  \n",
    "\n",
    "If you have experience working in machine learning, you must make some adjustments when working with time series.\n",
    "\n",
    "## 1) Time-series features should be handled with care\n",
    "As a data scientist, you may already be used to creating features, either manually (feature engineering) or automatically (feature learning). Either way, creating features is one of the most important and time-consuming tasks in analysis.\n",
    "\n",
    "(https://www.datascience.com/blog/time-series-forecasting-machine-learning-differences)\n",
    "\n",
    "\n",
    "# Data Split\n",
    "(https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "\n",
    "# 전처리 및 핸들링 팁\n",
    "(https://sacko.tistory.com/53?category=647946)\n",
    "\n",
    "\n",
    "# 과적합 및 기타 엄청난 강의자료\n",
    "(https://rfriend.tistory.com/187)\n",
    "\n",
    "\n",
    "# 시계열 강의자료\n",
    "(https://datascienceschool.net/notebook/TIME-SERIES-ANALYSIS/)\n",
    "\n",
    "\n",
    "# 머신러닝 강의록\n",
    "(https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/)\n",
    "\n",
    "# Cheet sheet\n",
    "(https://medium.com/machine-learning-in-practice/cheat-sheet-of-machine-learning-and-python-and-math-cheat-sheets-a4afe4e791b6)  \n",
    "(https://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/)  \n",
    "(https://www.favouriteblog.com/essential-cheat-sheets-for-machine-learning-python-and-maths/)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
